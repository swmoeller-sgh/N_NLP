Search.setIndex({"docnames": ["annotated_transformer", "hugging_faces", "index", "test_file"], "filenames": ["annotated_transformer.rst", "hugging_faces.rst", "index.rst", "test_file.rst"], "titles": ["The documented BERT from Sebastian", "Working with pipelines", "Welcome to Neural language processing (NLP)\u2019s documentation!", "Test file for sphinx"], "terms": {"bert": 2, "stand": [], "bidirect": [], "encod": [], "represent": [0, 1], "To": [], "put": [], "simpl": [], "word": [], "extract": [], "pattern": [], "from": [1, 2], "data": [], "embed": [], "pass": [], "through": [], "an": 1, "itself": [], "i": [0, 1], "architectur": [], "stack": [], "togeth": [], "It": [], "which": 1, "mean": 0, "dure": [], "train": 0, "consid": [], "context": [0, 1], "both": [], "left": [], "right": [], "vocabulari": 0, "achiev": [], "state": [], "art": [], "perform": [], "task": 1, "like": [], "question": [], "answer": [], "natur": [], "infer": [], "classif": 0, "gener": 0, "understand": 0, "evalu": [], "glue": [], "accept": [], "2": [], "sentenc": 0, "input": 1, "more": 1, "onli": [], "http": 0, "mccormickml": [], "com": 0, "2019": [], "05": [], "14": [], "tutori": [], "format": [], "entir": [], "program": 0, "broken": [], "down": [], "4": [], "section": [], "preprocess": [], "build": [], "model": 0, "loss": [], "optim": [], "sourc": [], "jalammar": [], "github": [], "io": [], "illustr": [], "refer": [], "follow": [], "were": [], "taken": [], "main": 1, "neptun": [], "ai": [], "blog": [], "how": [], "code": [], "us": [0, 1], "pytorch": [], "05_sphinx_test": 3, "20221022_test": 3, "print": 3, "in_text": [0, 3], "A": [0, 3], "sub": 3, "function": [], "someth": 3, "param": [], "text": [0, 3], "type": [0, 3], "str": [0, 3], "return": [0, 3], "rtype": [], "index": [0, 2], "modul": 2, "search": [0, 2], "page": 2, "And": [], "here": 1, "open": [], "topic": [], "rhe": [], "wewew": [], "toctre": [], "maxdepth": [], "5": [], "caption": [], "content": [], "instal": [], "support": [], "printing1": 3, "function1": 3, "paramet": [0, 3], "in_text2": 3, "test": 2, "testenen": 3, "none": 3, "n": [], "some": 3, "initi": 3, "class": [], "10_annotated_bert": [], "20221022_transformer_bert": [], "encoderdecod": [], "decod": [], "src_emb": [], "tgt_emb": [], "standard": [], "base": 0, "thi": [0, 1], "mani": 1, "other": 0, "intern": [], "share": [], "nn": [], "scriptmodul": [], "forward": [], "src": [], "tgt": [], "src_mask": [], "tgt_mask": [], "take": [], "mask": 0, "target": [], "sequenc": 0, "d_model": [], "vocab": [], "defin": [], "linear": [], "softmax": [], "step": [], "x": 0, "comput": [], "everi": 0, "call": [], "should": [], "overridden": [], "all": [0, 1], "subclass": [], "although": [], "recip": [], "need": 1, "within": [], "one": 0, "instanc": [], "afterward": [], "instead": [], "sinc": [], "former": [], "care": [], "run": [], "regist": [], "hook": [], "while": 1, "latter": [], "silent": [], "ignor": [], "them": 0, "clone": [], "produc": [], "ident": [], "layer": [], "core": [], "each": 0, "turn": [], "layernorm": [], "featur": 0, "ep": [], "1e": [], "06": [], "construct": [], "see": [], "citat": [], "detail": [], "sublayerconnect": [], "size": 0, "dropout": [], "residu": [], "connect": 0, "norm": [], "note": [0, 1], "simplic": [], "first": 0, "oppos": [], "last": [], "sublay": [], "appli": [], "ani": 0, "same": [], "encoderlay": [], "self_attn": [], "feed_forward": [], "made": [], "up": [], "self": [], "attn": [], "feed": [], "below": [], "figur": [], "memori": [], "decoderlay": [], "src_attn": [], "dummyoptim": [], "singl": 0, "updat": [], "closur": [], "callabl": [], "reevalu": [], "option": [], "most": 1, "unless": [], "otherwis": [], "specifi": [], "modifi": [], "grad": [], "field": [], "zero_grad": [], "set_to_non": [], "fals": [], "set": [], "gradient": [], "torch": [], "tensor": [], "zero": [], "bool": [], "have": 0, "lower": 0, "footprint": [], "can": 1, "modestli": [], "improv": [], "howev": [], "chang": [], "certain": [], "behavior": [], "For": 1, "exampl": [0, 1], "when": [], "user": [], "tri": [], "access": [], "manual": [], "op": [], "attribut": [], "full": 0, "0": 0, "behav": [], "differ": [], "If": [], "request": [], "true": [], "backward": [], "ar": 0, "guarante": [], "did": [], "receiv": [], "3": 0, "case": 0, "doe": [0, 1], "skip": [], "altogeth": [], "subsequent_mask": [], "out": 0, "subsequ": [], "posit": [], "multiheadedattent": [], "h": [], "number": 0, "head": [], "queri": [], "kei": [], "valu": [], "implement": [], "positionalencod": [], "max_len": [], "5000": [], "pe": [], "positionwisefeedforward": [], "d_ff": [], "ffn": [], "equat": [], "attent": [], "scale": [], "dot": [], "product": [], "make_model": [], "src_vocab": [], "tgt_vocab": [], "6": [], "512": [], "2048": [], "8": [], "helper": [], "hyperparamet": [], "batch": 0, "pad": 0, "object": 0, "hold": [], "static": [], "make_std_mask": [], "creat": 0, "hide": 0, "futur": [], "labelsmooth": [], "padding_idx": [], "smooth": [], "label": 1, "simplelosscomput": [], "criterion": [], "trainstat": [], "track": [], "token": 0, "data_gen": [], "v": [], "batch_siz": 0, "nbatch": [], "random": 0, "copi": [], "synthet": [], "rate": [], "model_s": [], "factor": [], "warmup": [], "we": [0, 1], "default": 1, "lambdalr": [], "avoid": [], "rais": [], "neg": [], "power": [], "run_epoch": [], "data_it": [], "loss_comput": [], "schedul": [], "mode": [], "accum_it": [], "train_stat": [], "epoch": [], "the_annotated_transform": [], "averag": [], "mtx2df": [], "m": [], "max_row": [], "max_col": [], "row_token": [], "col_token": [], "convert": 0, "dens": [], "matrix": [], "frame": [], "row": [], "column": [], "properti": [], "learn": [], "being": [], "xxx": 0, "anoth": [], "direct": [], "15_bert_exampl": 0, "training_exampl": 0, "generate_clean_sent": 0, "remov": 0, "punctuat": 0, "etc": 0, "two": 0, "One": 0, "without": 0, "contain": 0, "uniqu": 0, "string": 0, "word_list": 0, "interv": 0, "sffsfsf": [], "1": 0, "box": 0, "make_batch": 0, "int": 0, "84": 0, "max_pr": [], "maxlen": [], "23": 0, "alia": [], "swmoeller": [], "python": [], "n_nlp": [], "py": [], "fulli": 0, "document": [], "sebastian": 2, "autumn": 0, "2022": 0, "annot": [], "transform": 0, "sphinx": 2, "The": [1, 2], "file": 2, "purpos": [], "approach": [], "eiw": [], "wi": [], "fsf": [], "f": [], "ssfsfsf": [], "sfsf": [], "list": 0, "sdsdll": [], "dsdlsdsd": [], "dsld": [], "loc_sent": 0, "line": 0, "loc_word_list": 0, "duplic": 0, "generate_dictionari": 0, "in_word_list": 0, "start": 1, "dictionari": 0, "cl": 0, "alwai": 0, "sep": 0, "separ": 0, "end": 0, "truncat": 0, "equal": 0, "length": 0, "replac": 0, "origin": 0, "loc_word_dict": 0, "loc_number_dict": 0, "loc_vocab_s": 0, "dict": 0, "provid": [0, 1], "relat": 0, "convert_sentence_into_token": 0, "in_sent": 0, "in_word_dict": 0, "its": [], "specif": [], "e": 0, "select": 0, "check": 0, "alreadi": 0, "add": 0, "special": 0, "repres": 0, "second": 0, "in_max_pr": 0, "ambigu": 0, "languag": [0, 1], "surround": 0, "establish": 0, "mlm": 0, "predict": [0, 1], "what": 0, "ha": [0, 1], "been": [0, 1], "hidden": 0, "": [0, 1], "next": 0, "whether": 0, "given": [0, 1], "logic": 0, "sequenti": 0, "relationship": 0, "simpli": 0, "googl": 0, "process": 0, "rather": 0, "than": 0, "time": 0, "By": 0, "look": [0, 1], "allow": 0, "therefor": 0, "better": 0, "searcher": 0, "intent": 0, "clean": 0, "em": 0, "bed": 0, "ding": 0, "split": 0, "smaller": 0, "subword": 0, "charact": 0, "becaus": 0, "fix": 0, "30k": 0, "part": [0, 1], "vector": [0, 1], "background": 0, "www": 0, "techtarget": 0, "searchenterpriseai": 0, "item": 0, "individu": 0, "conver": 0, "obmit": 0, "in_maxlen": 0, "lst": 0, "medium": 0, "dhartidhami": 0, "7dc4d2ea54ca": 0, "get": 1, "idea": 1, "blank": 1, "where": 1, "find": 1, "correspond": 1, "person": 1, "locat": 1, "organ": 1, "let": 1, "inform": 1, "reduc": 1, "shorter": 1, "keep": 1, "import": 1, "aspect": 1, "referenc": 1, "you": 1, "prompt": 1, "auto": 1, "complet": 1, "remain": 1, "similar": 1, "found": 1, "phone": 1, "pair": 1, "translation_en_to_fr": 1, "easiest": 1, "wai": 1, "pick": 1, "want": 1, "hub": 1, "ll": 1, "tackl": 1, "challeng": 1, "classifi": 1, "haven": 1, "t": 1}, "objects": {"05_sphinx_test": [[3, 0, 0, "-", "20221022_test"]], "05_sphinx_test.20221022_test": [[3, 1, 1, "sphinx_test.20221022_test.printing", "printing"], [3, 1, 1, "sphinx_test.20221022_test.printing1", "printing1"]], "15_bert_example": [[0, 0, 0, "-", "training_example"]], "15_bert_example.training_example": [[0, 1, 1, "bert_example.training_example.convert_sentence_into_tokens", "convert_sentence_into_tokens"], [0, 1, 1, "bert_example.training_example.generate_clean_sentence", "generate_clean_sentence"], [0, 1, 1, "bert_example.training_example.generate_dictionary", "generate_dictionary"], [0, 1, 1, "bert_example.training_example.make_batch", "make_batch"], [0, 1, 1, "bert_example.training_example.random", "random"]]}, "objtypes": {"0": "py:module", "1": "py:function"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "function", "Python function"]}, "titleterms": {"welcom": 2, "neural": 2, "languag": 2, "process": 2, "nlp": 2, "": 2, "document": [0, 2], "purpos": [0, 3], "1": 1, "The": 0, "transform": [], "concept": 0, "indic": 2, "tabl": 2, "And": [], "here": [], "open": 2, "topic": 2, "list": 2, "test": 3, "best": [], "us": 3, "function": 3, "content": [0, 2], "file": [0, 3], "sphinx": 3, "next": [], "chapter": [], "n": [], "annot": [], "class": 3, "own": [], "transfer": [], "origin": [], "bert": 0, "from": 0, "sebastian": 0, "approach": 0, "clean": [], "sentenc": [], "sdsdsdsd": [], "gener": 1, "word": 0, "python": 0, "embed": 0, "some": 0, "definit": 0, "refer": 0, "work": 1, "pipelin": 1, "differ": 1, "util": 1, "model": 1, "sentiment": 1, "analysi": 1, "2": 1, "featur": 1, "extract": 1, "3": 1, "fill": 1, "mask": 1, "4": 1, "ner": 1, "name": 1, "entiti": 1, "recognit": 1, "5": 1, "question": 1, "answer": 1, "6": 1, "summar": 1, "7": 1, "text": 1, "8": 1, "translat": 1, "9": 1, "zero": 1, "shot": 1, "classif": 1}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.todo": 2, "sphinx": 57}, "alltitles": {"Purpose": [[3, "purpose"], [0, "purpose"]], "Used classes and functions": [[3, "used-classes-and-functions"]], "Test file for sphinx": [[3, "module-05_sphinx_test.20221022_test"]], "Welcome to Neural language processing (NLP)\u2019s documentation!": [[2, "welcome-to-neural-language-processing-nlp-s-documentation"]], "Table of content": [[2, null]], "List of open topics": [[2, "list-of-open-topics"]], "Indices and tables": [[2, "indices-and-tables"]], "The documented BERT from Sebastian": [[0, "the-documented-bert-from-sebastian"]], "Contents": [[0, "contents"]], "Approach in python file": [[0, "approach-in-python-file"]], "Concept": [[0, "concept"]], "word embedding": [[0, "word-embedding"]], "Some definition": [[0, "some-definition"]], "Reference": [[0, "reference"]], "Working with pipelines": [[1, "working-with-pipelines"]], "Different utilizations of models": [[1, "different-utilizations-of-models"]], "1. Sentiment analysis": [[1, "sentiment-analysis"]], "2. feature-extraction": [[1, "feature-extraction"]], "3. fill-mask": [[1, "fill-mask"]], "4. ner (named entity recognition)": [[1, "ner-named-entity-recognition"]], "5. question-answering": [[1, "question-answering"]], "6. summarization": [[1, "summarization"]], "7. text-generation": [[1, "text-generation"]], "8. translation": [[1, "translation"]], "9. zero-shot-classification": [[1, "zero-shot-classification"]]}, "indexentries": {"15_bert_example.training_example": [[0, "module-15_bert_example.training_example"]], "convert_sentence_into_tokens() (in module 15_bert_example.training_example)": [[0, "bert_example.training_example.convert_sentence_into_tokens"]], "generate_clean_sentence() (in module 15_bert_example.training_example)": [[0, "bert_example.training_example.generate_clean_sentence"]], "generate_dictionary() (in module 15_bert_example.training_example)": [[0, "bert_example.training_example.generate_dictionary"]], "make_batch() (in module 15_bert_example.training_example)": [[0, "bert_example.training_example.make_batch"]], "module": [[0, "module-15_bert_example.training_example"]], "random() (in module 15_bert_example.training_example)": [[0, "bert_example.training_example.random"]]}})